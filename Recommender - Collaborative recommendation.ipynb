{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #computing\n",
    "from lightfm.datasets import fetch_movielens #dataset\n",
    "from lightfm import LightFM # model\n",
    "from lightfm.evaluation import precision_at_k #predictions\n",
    "from lightfm.evaluation import auc_score  #predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 49906 stored elements in COOrdinate format>, 'test': <943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 5469 stored elements in COOrdinate format>, 'item_features': <1682x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 1682 stored elements in Compressed Sparse Row format>, 'item_feature_labels': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
      "       'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
      "       'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object), 'item_labels': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
      "       'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
      "       'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "# fetch dataset\n",
    "data = fetch_movielens(min_rating =4.0)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 49906 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "print(repr(data['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 5469 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "print(repr(data['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Weighted Approximate-Rank Pairwise model\n",
    " - or WARP is an implicit feedback model: all interactions in the training matrix are treated as positive signals, and products that users did not interact with they implicitly do not like. The goal of the model is to score these implicit positives highly while assigining low scores to implicit negatives.\n",
    " - For every pass through the data — an epoch — the model learns to fit the data more and more closely. The model fit method will be executed on 2 threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.94 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1dfa28c50b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create model\n",
    "model = LightFM(loss='warp') # loss measures the difference between our models prediciton and the desired outcome\n",
    "\n",
    "#train model\n",
    "%time model.fit(data['train'], epochs= 30, num_threads=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring precision in 2 ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #1. Pecision@K method which measures the proportion of positive items among the K highest-ranked items. Meaning that it doesn't matter how good or bad the rest of the ranking is as long as the first K items are mostly positive. This would be an appropriate metric when showing the users the very top of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using precision@K:\n",
      "Train precision: 0.56\n",
      "Test precision: 0.09\n"
     ]
    }
   ],
   "source": [
    "#measure the precision in both train and test in 2 ways\n",
    "print(\"Using precision@K:\")\n",
    "print(\"Train precision: %.2f\" % precision_at_k(model, data['train'], k=5).mean())\n",
    "print(\"Test precision: %.2f\" % precision_at_k(model, data['test'], k=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. AUC method which measures the quality of the overall ranking. In the binary case, it can be interpreted as the probability that a randomly chosen positive item is ranked higher than a randomly chosen negative item.An AUC close to 1.0 will suggest that the  ordering is correct: and this can be true even if none of the first K items are positives. This is more appropriate when high quality throughout is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AUC score:\n",
      "Train precision: 0.96\n",
      "Test precision: 0.92\n"
     ]
    }
   ],
   "source": [
    "print(\"Using AUC score:\")\n",
    "print(\"Train precision: %.2f\" % auc_score(model, data['train']).mean())\n",
    "print(\"Test precision: %.2f\" % auc_score(model, data['test']).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result interpretation: The model fits the train set better than the test set, as it should be expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n"
     ]
    }
   ],
   "source": [
    "print(data['test'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  To make predictions for a given user, pass the id of that user and the ids of all products for which predictions are requested into the predict method of the model.\n",
    "  Note :  # lightfm considers ratings that are  == 5 positive and <=4 negative, to make it binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_recommendation(model, data, user_ids):\n",
    "    \n",
    "    #number of items and number of movies in training data\n",
    "    n_users, n_items = data['test'].shape\n",
    "    \n",
    "    # generate recommendation for each user\n",
    "    for user_id in user_ids:\n",
    "        \n",
    "        # movies the users already like        \n",
    "        # get the list of positive ratings from data in compressed sparsed row format\n",
    "        # duplicate entries in the matrix will be sparsed together by using tocsr() from scipy\n",
    "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
    "    \n",
    "        #movies the model predicts they like\n",
    "        scores = model.predict(user_id, np.arange(n_items))\n",
    "        \n",
    "        #rank them from most liked to least\n",
    "        top_items = data['item_labels'][np.argsort(-scores)]\n",
    "        \n",
    "        #check results\n",
    "        print(\"User %s\" % user_id)\n",
    "        print(\"        Known positives:\")\n",
    "        \n",
    "        for x in known_positives[:5]:\n",
    "            print(\"           %s\" % x)\n",
    "        \n",
    "        print(\"        Recommended:\")\n",
    "        \n",
    "        for x in top_items[:5]:\n",
    "            print(\"           %s\" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get recommendations for given user(s), pass the id of those users, the fitted model, and the data set to the get_recommendation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 145\n",
      "        Known positives:\n",
      "           Devil's Own, The (1997)\n",
      "           Contact (1997)\n",
      "           Full Monty, The (1997)\n",
      "           Good Will Hunting (1997)\n",
      "           Wings of the Dove, The (1997)\n",
      "        Recommended:\n",
      "           English Patient, The (1996)\n",
      "           L.A. Confidential (1997)\n",
      "           Full Monty, The (1997)\n",
      "           Boogie Nights (1997)\n",
      "           Good Will Hunting (1997)\n",
      "User 23\n",
      "        Known positives:\n",
      "           Twelve Monkeys (1995)\n",
      "           Babe (1995)\n",
      "           Dead Man Walking (1995)\n",
      "           Seven (Se7en) (1995)\n",
      "           Usual Suspects, The (1995)\n",
      "        Recommended:\n",
      "           Star Wars (1977)\n",
      "           Return of the Jedi (1983)\n",
      "           Fargo (1996)\n",
      "           Godfather, The (1972)\n",
      "           Twelve Monkeys (1995)\n",
      "User 45\n",
      "        Known positives:\n",
      "           Twelve Monkeys (1995)\n",
      "           Star Wars (1977)\n",
      "           Welcome to the Dollhouse (1995)\n",
      "           Fargo (1996)\n",
      "           Phenomenon (1996)\n",
      "        Recommended:\n",
      "           English Patient, The (1996)\n",
      "           Contact (1997)\n",
      "           Air Force One (1997)\n",
      "           Titanic (1997)\n",
      "           L.A. Confidential (1997)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "get_recommendation(model, data, [145,23,45])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
